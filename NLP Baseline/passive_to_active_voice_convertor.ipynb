{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HknNbVI5_EFg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6gou59DAVKr",
        "outputId": "dbe0d1d2-5333-40b6-9c52-5d9256fbdc50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "pronouns = {'her ': 'she ', 'him ': 'he ', 'whom ': 'who ', 'me ': 'I ', 'us ': 'we ', 'them ': 'they '}\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "H6CRe8HsCjg1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"The entire stretch of highway was paved by the crew\")"
      ],
      "metadata": {
        "id": "vAe4A87IDMMw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc.sents:\n",
        "    try:\n",
        "        sent_list = []\n",
        "        for token in sent:\n",
        "            sent_list.append(token)\n",
        "\n",
        "        main_verb_index = None\n",
        "        agent_index = None\n",
        "        recipient_index = None\n",
        "        agent = ''\n",
        "        append = False\n",
        "        inflection = ''\n",
        "        agent_article = ''\n",
        "        start_word = ''\n",
        "        sentence_remainder = []\n",
        "\n",
        "        index_counter = 0\n",
        "\n",
        "        for token in sent_list:\n",
        "            if token.dep_ in ['nsubjpass', 'nsubj']:\n",
        "                recipient_index = index_counter\n",
        "                recipient = token.lower_\n",
        "                article_list = [t.text for t in token.lefts]\n",
        "                try:\n",
        "                    compound_article = ' '.join(article_list).lower()\n",
        "                except:\n",
        "                    compound_article = ''\n",
        "            if token.dep_ == 'ROOT':\n",
        "                main_verb_index == index_counter\n",
        "                main_verb = token.text\n",
        "                base_form_of_main_verb = token.lemma_\n",
        "                # TODO: convert VBN to VBD\n",
        "                # if token.tag_ == 'VBN':\n",
        "\n",
        "            if token.dep_ == 'agent':\n",
        "                agent_index = index_counter\n",
        "                agent_children_list = [t.text for t in token.rights]\n",
        "                agent_children_right = ' '.join(agent_children_list)\n",
        "                agent = token.text + ' ' + agent_children_right\n",
        "                agent_children_left = [t.text for t in token.lefts]\n",
        "                append = True\n",
        "            if agent and not token.is_punct:\n",
        "                sentence_remainder.append(token)\n",
        "            if token.is_punct:\n",
        "                punct = token.text\n",
        "            if token.dep_ == 'pobj':\n",
        "               append = False\n",
        "               if not agent:\n",
        "                   agent = token.text\n",
        "            if token.text in ['may', 'must', 'might', 'could', 'will']:\n",
        "                inflection = ' ' + token.text + ' '\n",
        "\n",
        "            index_counter += 1\n",
        "        if punct in ['?']:\n",
        "            for token in sent:\n",
        "                if token.text in ['Can', 'May']:\n",
        "                    start_word = token.text\n",
        "                    break\n",
        "\n",
        "        for key, value in pronouns.items():\n",
        "            if key in agent.lower() + ' ':\n",
        "                agent = value.strip()\n",
        "        index = 0\n",
        "        for t in sentence_remainder:\n",
        "            if t.pos_ in ['DET'] and index >= 2:\n",
        "                agent_article = t.text\n",
        "                index += 1\n",
        "\n",
        "        if recipient_index < agent_index:\n",
        "            print('-'*50+'\\n {}'.format(\n",
        "                sent)+'\\n Active voice skeleton:{} {} {} {}{} {} {}{}'.format(\n",
        "                    start_word, agent_article, agent, inflection, main_verb, compound_article, recipient, punct).replace(\n",
        "                        'by ', ''))\n",
        "            print('Base form of main verb: {}'.format(base_form_of_main_verb))\n",
        "    except:\n",
        "        print(sent)\n",
        "        for token in sent:\n",
        "            print('Text: ' + token.text + ' |   Dep: ' + token.dep_ + ' |   Tag: ' + token.tag_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKRep0gzDCSQ",
        "outputId": "aa59948b-f79a-43e4-ae0f-ab81a9c22f74"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            " The entire stretch of highway was paved by the crew\n",
            " Active voice skeleton:  crew paved the entire stretch.\n",
            "Base form of main verb: pave\n"
          ]
        }
      ]
    }
  ]
}